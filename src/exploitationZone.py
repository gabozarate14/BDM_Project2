import configparser
import pyspark
from pyspark import SparkConf
from pyspark.sql import SparkSession
import os
import sys
from datetime import datetime
import json
import happybase

CONFIG_ROUTE = 'utils/config.cfg'


def readFormatted(connection, table_name):
    table = connection.table(table_name)
    rdd = spark.sparkContext.parallelize(list(table.scan())).map(
        lambda r: json.loads(r[1][b'cf:value'].decode())).cache()
    return rdd


def formatPredKPI(listDict):
    dict1 = listDict[0]
    dict2 = listDict[1]
    # KPI = population / Total. Euros/m2 construït
    try:
        kpi = round(dict1['RFD'] / float(dict2['Total. Euros/m2 construït']),4)
    except:
        kpi = 0

    return {**dict1, **dict2, 'kpi': kpi}


if __name__ == '__main__':
    # Get the parameters
    config = configparser.ConfigParser()
    config.read(CONFIG_ROUTE)
    # Server info
    host = config.get('data_server', 'host')
    # Spark
    pyspark_python = config.get('pyspark', 'python')
    pyspark_driver_python = config.get('pyspark', 'driver_python')
    # Hadoop
    hadoop_home = config.get('hadoop', 'home')
    # Hbase tables
    idealista_table_name = config.get('hbase', 'idealista_table')
    income_table_name = config.get('hbase', 'income_table')
    price_table_name = config.get('hbase', 'price_table')
    district_table_name = config.get('hbase', 'district_table')
    neighborhood_table_name = config.get('hbase', 'neighborhood_table')

    # Connect to HBase
    connection = happybase.Connection(host=host, port=9090)
    connection.open()

    # Set Spark
    os.environ["HADOOP_HOME"] = hadoop_home
    sys.path.append(hadoop_home + "\\bin")
    os.environ["PYSPARK_PYTHON"] = pyspark_python
    os.environ["PYSPARK_DRIVER_PYTHON"] = pyspark_driver_python

    # Set Spark
    conf = SparkConf() \
        .set("spark.master", "local") \
        .set("spark.app.name", "Exploitation Zone")

    # Create the session
    spark = SparkSession.builder \
        .config(conf=conf) \
        .getOrCreate()

    income_rdd = readFormatted(connection, income_table_name)
    price_rdd = readFormatted(connection, price_table_name)
    # idealista_rdd = readFormatted(connection, idealista_table_name)

    # .map(lambda r: r["Preu_mitja_habitatge"]).distinct()
    ans_rdd = price_rdd.filter(lambda r: (r["idNeighborhood"] == 'Q3596096') and (r["Any"] == '2015'))

    ans_rdd = income_rdd.map(lambda r: (
    (str(r['year']) if r['year'] else '') + (r['idNeighborhood'] if r['idNeighborhood'] else ''), r)).join(
        price_rdd.map(
            lambda r: ((str(r['Any']) if r['Any'] else '') + (r['idNeighborhood'] if r['idNeighborhood'] else ''), r)))

    ans_rdd = ans_rdd.map(lambda r: formatPredKPI(r[1]))

    for f in ans_rdd.collect():
        print(f)

    connection.close()
